{
    "cells": [
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "# CapsWriter-Offline 热词与纠错系统演示\n",
                "\n",
                "本 Notebook 整合了 `PhonemeCorrector` (音素纠错) 和 `RectificationRAG` (纠错历史检索) 的核心逻辑，是一个完全自包含的演示环境。\n",
                "\n",
                "需要依赖：\n",
                "\n",
                "```\n",
                "pypinyin\n",
                "numba\n",
                "numpy\n",
                "```"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 37,
            "metadata": {},
            "outputs": [],
            "source": [
                "import re\n",
                "import time\n",
                "import numpy as np\n",
                "import threading\n",
                "import logging\n",
                "from typing import List, Tuple, Dict, Set, Optional, Literal\n",
                "from dataclasses import dataclass\n",
                "from difflib import SequenceMatcher\n",
                "from collections import defaultdict\n",
                "from pathlib import Path\n",
                "\n",
                "# 配置日志\n",
                "logging.basicConfig(level=logging.INFO, format='%(levelname)s: %(message)s')\n",
                "logger = logging.getLogger(\"hotword\")\n",
                "\n",
                "# 尝试导入依赖\n",
                "try:\n",
                "    from pypinyin import pinyin, Style\n",
                "    HAS_PYPINYIN = True\n",
                "except ImportError:\n",
                "    HAS_PYPINYIN = False\n",
                "    print(\"Warning: pypinyin not found. Use 'pip install pypinyin' for full functionality.\")\n",
                "\n",
                "try:\n",
                "    from numba import njit\n",
                "    HAS_NUMBA = True\n",
                "except ImportError:\n",
                "    HAS_NUMBA = False\n",
                "    def njit(func): return func\n",
                "    print(\"Note: numba not found. Running in pure Python mode.\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 1. 基础数据结构与音素处理"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 38,
            "metadata": {},
            "outputs": [],
            "source": [
                "@dataclass\n",
                "class Phoneme:\n",
                "    value: str\n",
                "    lang: str  # 'zh', 'en', 'num'\n",
                "    is_word_start: bool = False\n",
                "    is_word_end: bool = False\n",
                "    char_start: int = 0\n",
                "    char_end: int = 0\n",
                "\n",
                "    @property\n",
                "    def is_tone(self):\n",
                "        return self.lang == 'zh' and self.value.isdigit()\n",
                "\n",
                "    @property\n",
                "    def info(self):\n",
                "        return (self.value, self.lang, self.is_word_start, self.is_word_end, self.is_tone, self.char_start, self.char_end)\n",
                "\n",
                "def normalize_text(text: str) -> str:\n",
                "    text = re.sub(r'([a-z])([A-Z])', r'\\1 \\2', text)\n",
                "    text = re.sub(r'([0-9])([a-zA-Z])', r'\\1 \\2', text)\n",
                "    text = re.sub(r'([a-zA-Z])([0-9])', r'\\1 \\2', text)\n",
                "    text = re.sub(r'[^a-zA-Z0-9\\u4e00-\\u9fff\\s]', ' ', text)\n",
                "    return text.lower().strip()\n",
                "\n",
                "def split_mixed_label(input_str: str) -> List[str]:\n",
                "    tokens = []\n",
                "    for part in input_str.split():\n",
                "        i, n = 0, len(part)\n",
                "        while i < n:\n",
                "            if '\\u4e00' <= part[i] <= '\\u9fff':\n",
                "                tokens.append(part[i])\n",
                "                i += 1\n",
                "            else:\n",
                "                start = i\n",
                "                while i < n and not ('\\u4e00' <= part[i] <= '\\u9fff'):\n",
                "                    i += 1\n",
                "                tokens.append(part[start:i])\n",
                "    return tokens\n",
                "\n",
                "def _zh_char_to_phonemes(char: str) -> List[Phoneme]:\n",
                "    if not HAS_PYPINYIN: return [Phoneme(char, 'zh', True, True)]\n",
                "    try:\n",
                "        py_initials = pinyin(char, style=Style.INITIALS, strict=False)\n",
                "        py_finals = pinyin(char, style=Style.FINALS, strict=False)\n",
                "        py_tone3 = pinyin(char, style=Style.TONE3, strict=False)\n",
                "        if not py_tone3 or not py_tone3[0][0]:\n",
                "             return [Phoneme(char, 'zh', True, True)]\n",
                "        res = []\n",
                "        has_init = py_initials and py_initials[0][0]\n",
                "        if has_init: res.append(Phoneme(py_initials[0][0], 'zh', is_word_start=True))\n",
                "        if py_finals and py_finals[0][0]: res.append(Phoneme(py_finals[0][0], 'zh', is_word_start=not has_init))\n",
                "        py_val = py_tone3[0][0]\n",
                "        tone = py_val[-1] if py_val[-1].isdigit() else '0'\n",
                "        res.append(Phoneme(tone, 'zh', is_word_end=True))\n",
                "        return res\n",
                "    except:\n",
                "        return [Phoneme(char, 'zh', True, True)]\n",
                "\n",
                "def get_phoneme_info(text: str) -> List[Phoneme]:\n",
                "    phoneme_seq = []\n",
                "    pos = 0\n",
                "    while pos < len(text):\n",
                "        char = text[pos]\n",
                "        if '\\u4e00' <= char <= '\\u9fff':\n",
                "            phons = _zh_char_to_phonemes(char)\n",
                "            for p in phons:\n",
                "                p.char_start, p.char_end = pos, pos + 1\n",
                "                phoneme_seq.append(p)\n",
                "            pos += 1\n",
                "        elif char.isalnum():\n",
                "            start = pos\n",
                "            while pos < len(text) and text[pos].isalnum(): pos += 1\n",
                "            token = text[start:pos].lower()\n",
                "            lang = 'num' if token.isdigit() else 'en'\n",
                "            # 简单处理：英文也切分为字母以便模糊匹配\n",
                "            for i, c in enumerate(token):\n",
                "                phoneme_seq.append(Phoneme(c, lang, i==0, i==len(token)-1, start, pos))\n",
                "        else: pos += 1\n",
                "    return phoneme_seq\n",
                "\n",
                "def get_phoneme_seq(text: str) -> List[Phoneme]:\n",
                "    # 为 Rectification 使用的简单版本\n",
                "    normalized = normalize_text(text)\n",
                "    res = []\n",
                "    for token in split_mixed_label(normalized):\n",
                "        if re.match(r'^[a-z0-9]+$', token):\n",
                "            lang = 'num' if token.isdigit() else 'en'\n",
                "            res.extend([Phoneme(c, lang, True, True) for c in token])\n",
                "        else:\n",
                "            res.extend(_zh_char_to_phonemes(token))\n",
                "    return res"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 2. 核心算法 (编辑距离与打分)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 39,
            "metadata": {},
            "outputs": [],
            "source": [
                "@njit\n",
                "def _fuzzy_substring_distance_numba(main_codes: np.ndarray, sub_codes: np.ndarray) -> float:\n",
                "    n, m = len(sub_codes), len(main_codes)\n",
                "    if n == 0: return 0.0\n",
                "    dp = np.zeros((n + 1, m + 1))\n",
                "    for i in range(n + 1): dp[i, 0] = i\n",
                "    for j in range(m + 1): dp[0, j] = 0\n",
                "    for i in range(1, n + 1):\n",
                "        for j in range(1, m + 1):\n",
                "            cost = 0.0 if sub_codes[i-1] == main_codes[j-1] else 1.0\n",
                "            dp[i, j] = min(dp[i-1, j] + 1.0, dp[i, j-1] + 1.0, dp[i-1, j-1] + cost)\n",
                "    return np.min(dp[n, :])\n",
                "\n",
                "def fast_substring_score(hw_compare: List[Tuple], sub_seg: List[Tuple]) -> float:\n",
                "    n, m = len(hw_compare), len(sub_seg)\n",
                "    if n == 0: return 0.0\n",
                "    hw_vals = [x[0] for x in hw_compare]\n",
                "    sub_vals = [x[0] for x in sub_seg]\n",
                "    dp = [[0.0]*(m+1) for _ in range(n+1)]\n",
                "    for i in range(n+1): dp[i][0] = i\n",
                "    for j in range(m+1): dp[0][j] = 0\n",
                "    for i in range(1, n+1):\n",
                "        for j in range(1, m+1):\n",
                "            cost = 0.0 if hw_vals[i-1] == sub_vals[j-1] else 1.0\n",
                "            dp[i][j] = min(dp[i-1][j]+1, dp[i][j-1]+1, dp[i-1][j-1]+cost)\n",
                "    min_dist = min(dp[n])\n",
                "    return 1.0 - (min_dist / n)\n",
                "\n",
                "def fuzzy_substring_distance(main_seq: List[Phoneme], sub_seq: List[Phoneme]) -> float:\n",
                "    m_vals = np.array([hash(p.value) % 1000000 for p in main_seq], dtype=np.int32)\n",
                "    s_vals = np.array([hash(p.value) % 1000000 for p in sub_seq], dtype=np.int32)\n",
                "    return _fuzzy_substring_distance_numba(m_vals, s_vals)\n",
                "\n",
                "def extract_diff_fragments(wrong: str, right: str) -> List[str]:\n",
                "    # 简单版的差异提取实现\n",
                "    s1 = split_mixed_label(normalize_text(wrong))\n",
                "    s2 = split_mixed_label(normalize_text(right))\n",
                "    matcher = SequenceMatcher(None, s1, s2)\n",
                "    fragments = []\n",
                "    for tag, i1, i2, j1, j2 in matcher.get_opcodes():\n",
                "        if tag in ('replace', 'delete'):\n",
                "            fragments.append(\" \".join(s1[i1:i2]))\n",
                "        if tag in ('replace', 'insert'):\n",
                "            fragments.append(\" \".join(s2[j1:j2]))\n",
                "    return [f for f in fragments if f.strip()]"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 3. RAG 检索器与纠错器"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 40,
            "metadata": {},
            "outputs": [],
            "source": [
                "class PhonemeIndex:\n",
                "    def __init__(self):\n",
                "        self.index = defaultdict(list)\n",
                "    def add(self, hw: str, phonemes: List[Phoneme]):\n",
                "        if not phonemes: return\n",
                "        key = phonemes[0].value\n",
                "        self.index[key].append((hw, [p.value for p in phonemes]))\n",
                "    def get_candidates(self, input_phonemes: List[Phoneme]):\n",
                "        seen_keys = {p.value for p in input_phonemes}\n",
                "        candidates = []\n",
                "        for k in seen_keys:\n",
                "            candidates.extend(self.index.get(k, []))\n",
                "        return candidates\n",
                "\n",
                "class FastRAG:\n",
                "    def __init__(self, threshold=0.6):\n",
                "        self.threshold = threshold\n",
                "        self.index = PhonemeIndex()\n",
                "        self.hotwords_data = {} \n",
                "    def add_hotword(self, hw: str):\n",
                "        phons = get_phoneme_info(hw)\n",
                "        self.index.add(hw, phons)\n",
                "        self.hotwords_data[hw] = phons\n",
                "    def search(self, input_phonemes: List[Phoneme]):\n",
                "        input_vals = np.array([hash(p.value) % 1000000 for p in input_phonemes], dtype=np.int32)\n",
                "        candidates = self.index.get_candidates(input_phonemes)\n",
                "        results = []\n",
                "        for hw, hw_phone_vals in candidates:\n",
                "            hw_np = np.array([hash(v) % 1000000 for v in hw_phone_vals], dtype=np.int32)\n",
                "            dist = _fuzzy_substring_distance_numba(input_vals, hw_np)\n",
                "            score = 1.0 - (dist / len(hw_phone_vals))\n",
                "            if score >= self.threshold: results.append((hw, score))\n",
                "        return sorted(results, key=lambda x: x[1], reverse=True)\n",
                "\n",
                "class PhonemeCorrector:\n",
                "    def __init__(self, threshold=0.7):\n",
                "        self.rag = FastRAG(threshold=threshold - 0.1)\n",
                "        self.threshold = threshold\n",
                "    def update_hotwords(self, hotwords_text: str):\n",
                "        \"\"\"支持多行字符串格式的热词加载\"\"\"\n",
                "        for line in hotwords_text.split('\\n'):\n",
                "            hw = line.strip()\n",
                "            if hw and not hw.startswith('#'):\n",
                "                self.rag.add_hotword(hw)\n",
                "    def load_hotwords_file(self, file_path: str):\n",
                "        path = Path(file_path)\n",
                "        if path.exists():\n",
                "            self.update_hotwords(path.read_text(encoding='utf-8'))\n",
                "    def correct(self, text: str):\n",
                "        input_phons = get_phoneme_info(text)\n",
                "        candidates = self.rag.search(input_phons)\n",
                "        input_processed = [p.info for p in input_phons]\n",
                "        matches = []\n",
                "        for hw, _ in candidates:\n",
                "            hw_phons = self.rag.hotwords_data[hw]\n",
                "            hw_compare = [p.info[:5] for p in hw_phons]\n",
                "            target_len = len(hw_compare)\n",
                "            for i in range(len(input_processed) - target_len + 1):\n",
                "                sub = input_processed[i:i+target_len]\n",
                "                if sub[0][1] != 'en' and sub[0][0] != hw_compare[0][0]: continue\n",
                "                score = fast_substring_score(hw_compare, sub)\n",
                "                if score >= self.threshold:\n",
                "                    matches.append({'start': sub[0][5], 'end': sub[-1][6], 'hw': hw, 'score': score})\n",
                "        matches.sort(key=lambda x: x['score'], reverse=True)\n",
                "        result_text = list(text)\n",
                "        used = [False] * len(text)\n",
                "        final_matched = []\n",
                "        for m in matches:\n",
                "            if any(used[m['start']:m['end']]): continue\n",
                "            for i in range(m['start'], m['end']): used[i] = True\n",
                "            result_text[m['start']:m['end']] = list(m['hw'])\n",
                "            final_matched.append((m['hw'], m['score']))\n",
                "        return \"\".join(result_text), final_matched"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 4. Rectification (纠错历史检索)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 41,
            "metadata": {},
            "outputs": [],
            "source": [
                "class RectificationRAG:\n",
                "    def __init__(self, threshold=0.5):\n",
                "        self.records = []\n",
                "        self.threshold = threshold\n",
                "    def add_history(self, wrong: str, right: str):\n",
                "        fragments = extract_diff_fragments(wrong, right)\n",
                "        if not fragments: fragments = [wrong]\n",
                "        record = {\n",
                "            'wrong': wrong, \n",
                "            'right': right, \n",
                "            'fragment_phonemes': {f: get_phoneme_seq(f) for f in fragments}\n",
                "        }\n",
                "        self.records.append(record)\n",
                "    def load_rectify_text(self, text: str):\n",
                "        \"\"\"支持 --- 分隔的项目纠错历史格式\"\"\"\n",
                "        blocks = text.split('---')\n",
                "        for block in blocks:\n",
                "            lines = [l.strip() for l in block.strip().split('\\n') if l.strip() and not l.strip().startswith('#')]\n",
                "            if len(lines) >= 2:\n",
                "                self.add_history(lines[0], lines[1])\n",
                "    def load_rectify_file(self, file_path: str):\n",
                "        path = Path(file_path)\n",
                "        if path.exists():\n",
                "            self.load_rectify_text(path.read_text(encoding='utf-8'))\n",
                "    def search(self, text: str):\n",
                "        input_phons = get_phoneme_seq(text)\n",
                "        results = []\n",
                "        for rec in self.records:\n",
                "            best_score = 0.0\n",
                "            for f, f_phons in rec['fragment_phonemes'].items():\n",
                "                if not f_phons: continue\n",
                "                score = 1.0 - (fuzzy_substring_distance(input_phons, f_phons) / len(f_phons))\n",
                "                best_score = max(best_score, score)\n",
                "            if best_score >= self.threshold: results.append((rec['wrong'], rec['right'], best_score))\n",
                "        return sorted(results, key=lambda x: x[2], reverse=True)"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 5. 综合演示 (Demo)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 42,
            "metadata": {},
            "outputs": [],
            "source": [
                "hotwords_data = \"\"\"\n",
                "    Claude\n",
                "    Bilibili\n",
                "    Microsoft\n",
                "    买当劳\n",
                "    肯德基\n",
                "    # 这是一个注释\n",
                "    VsCode\n",
                "\"\"\"\n",
                "    \n",
                "rectify_data = \"\"\"\n",
                "# 纠错历史演示\n",
                "把那个锯子给我\n",
                "把那个句子给我\n",
                "---\n",
                "cloud code is good\n",
                "Claude Code is good\n",
                "---\n",
                "今天天其不错\n",
                "今天天气不错\n",
                "\"\"\"\n",
                "\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# 初始化纠错器和检索器\n",
                "corrector = PhonemeCorrector(threshold=0.8)\n",
                "rectifier = RectificationRAG(threshold=0.5)\n",
                "\n",
                "# 从字符串加载热词\n",
                "corrector.update_hotwords(hotwords_data)\n",
                "rectifier.load_rectify_text(rectify_data)\n",
                "\n",
                "# 从文本文件加载热词\n",
                "# corrector.load_hotwords_file(\"hot.txt\")\n",
                "# rectifier.load_rectify_file(\"hot-rectify.txt\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 44,
            "metadata": {},
            "outputs": [],
            "source": [
                "test_cases_text = \"\"\"\n",
                "我想去吃买当劳和肯得鸡\n",
                "Hello klaude\n",
                "喜欢刷Bili Bili\n",
                "请把那个锯子发给我一下\n",
                "今天天及真的很好\n",
                "I think claud code is very good\n",
                "使用vs code编写代码\n",
                "\"\"\"\n",
                "\n",
                "cases = [l.strip() for l in test_cases_text.strip().split('\\n') if l.strip()]\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 45,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "\n",
                        "========================================\n",
                        "【综合纠错与检索演示】\n",
                        "========================================\n",
                        "\n",
                        "Case 1: '我想去吃买当劳和肯得鸡'\n",
                        "  [纠错后] 我想去吃买当劳和肯德基\n",
                        "  [匹配热词] [('肯德基', 1.0), ('买当劳', 1.0)]\n",
                        "  [RAG 历史匹配]\n",
                        "    - '把那个锯子给我' => '把那个句子给我' (相似度: 0.667)\n",
                        "    - '今天天其不错' => '今天天气不错' (相似度: 0.667)\n",
                        "\n",
                        "Case 2: 'Hello klaude'\n",
                        "  [纠错后] Hello klaude\n",
                        "  [RAG 历史匹配]\n",
                        "    - 'cloud code is good' => 'Claude Code is good' (相似度: 0.833)\n",
                        "\n",
                        "Case 3: '喜欢刷Bili Bili'\n",
                        "  [纠错后] 喜欢刷Bilibili\n",
                        "  [匹配热词] [('Bilibili', 1.0)]\n",
                        "\n",
                        "Case 4: '请把那个锯子发给我一下'\n",
                        "  [纠错后] 请把那个锯子发给我一下\n",
                        "  [RAG 历史匹配]\n",
                        "    - '把那个锯子给我' => '把那个句子给我' (相似度: 1.000)\n",
                        "\n",
                        "Case 5: '今天天及真的很好'\n",
                        "  [纠错后] 今天天及真的很好\n",
                        "  [RAG 历史匹配]\n",
                        "    - '今天天其不错' => '今天天气不错' (相似度: 0.667)\n",
                        "\n",
                        "Case 6: 'I think claud code is very good'\n",
                        "  [纠错后] I Claude code is very good\n",
                        "  [匹配热词] [('Claude', 0.8333333333333334)]\n",
                        "  [RAG 历史匹配]\n",
                        "    - 'cloud code is good' => 'Claude Code is good' (相似度: 0.833)\n",
                        "\n",
                        "Case 7: '使用vs code编写代码'\n",
                        "  [纠错后] 使用VsCode\n",
                        "  [匹配热词] [('VsCode', 1.0)]\n",
                        "  [RAG 历史匹配]\n",
                        "    - 'cloud code is good' => 'Claude Code is good' (相似度: 0.600)\n"
                    ]
                }
            ],
            "source": [
                "\n",
                "\n",
                "print(\"\\n\" + \"=\"*40)\n",
                "print(\"【综合纠错与检索演示】\")\n",
                "print(\"=\"*40)\n",
                "\n",
                "for i, t in enumerate(cases):\n",
                "    print(f\"\\nCase {i+1}: '{t}'\")\n",
                "    \n",
                "    # 步骤 1: 拼音纠错\n",
                "    res, matched = corrector.correct(t)\n",
                "    print(f\"  [纠错后] {res}\")\n",
                "    if matched: print(f\"  [匹配热词] {matched}\")\n",
                "    \n",
                "    # 步骤 2: RAG 历史检索\n",
                "    rag_results = rectifier.search(t)\n",
                "    if rag_results:\n",
                "        print(f\"  [RAG 历史匹配]\")\n",
                "        for w, r, s in rag_results:\n",
                "            print(f\"    - '{w}' => '{r}' (相似度: {s:.3f})\")\n"
            ]
        }
    ],
    "metadata": {
        "kernelspec": {
            "display_name": "capswriter",
            "language": "python",
            "name": "python3"
        },
        "language_info": {
            "codemirror_mode": {
                "name": "ipython",
                "version": 3
            },
            "file_extension": ".py",
            "mimetype": "text/x-python",
            "name": "python",
            "nbconvert_exporter": "python",
            "pygments_lexer": "ipython3",
            "version": "3.10.19"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 4
}
