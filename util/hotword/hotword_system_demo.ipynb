{
    "cells": [
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "# CapsWriter-Offline 独立热词与纠错系统 (Portable Version)\n",
                "\n",
                "本 Notebook 整合了音素处理 (algo_phoneme)、FastRAG 加速检索 (rag_fast)、拼音纠错 (PhonemeCorrector)、规则纠错 (RuleCorrector) 和纠错历史 RAG (RectificationRAG) 的完整逻辑。\n",
                "\n",
                "**依赖安装：**\n",
                "```bash\n",
                "pip install pypinyin numba numpy\n",
                "```"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 1,
            "metadata": {},
            "outputs": [],
            "source": [
                "import os\n",
                "import re\n",
                "import sys\n",
                "import time\n",
                "import threading\n",
                "import logging\n",
                "from typing import List, Tuple, Dict, Set, Optional, Literal, NamedTuple\n",
                "from dataclasses import dataclass\n",
                "from collections import defaultdict\n",
                "from difflib import SequenceMatcher\n",
                "\n",
                "# 设置日志\n",
                "logging.basicConfig(level=logging.INFO, format='%(levelname)s: %(message)s')\n",
                "logger = logging.getLogger(__name__)\n",
                "\n",
                "# 尝试导入 Numba 和 numpy\n",
                "try:\n",
                "    from numba import njit\n",
                "    import numpy as np\n",
                "    HAS_NUMBA = True\n",
                "except ImportError:\n",
                "    HAS_NUMBA = False\n",
                "    np = None\n",
                "\n",
                "# 尝试导入 pypinyin\n",
                "try:\n",
                "    from pypinyin import pinyin, Style\n",
                "    HAS_PYPINYIN = True\n",
                "except ImportError:\n",
                "    HAS_PYPINYIN = False\n",
                "    pinyin = None\n",
                "    Style = None\n",
                "    print(\"WARNING: pypinyin 未安装，将使用字符级降级处理。\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 1. 核心算法与数据结构\n",
                "包含 `Phoneme` 类定义、文本规范化处理和音素转换逻辑。"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 2,
            "metadata": {},
            "outputs": [],
            "source": [
                "@dataclass(frozen=True, slots=True)\n",
                "class Phoneme:\n",
                "    \"\"\"带语言属性的音素\"\"\"\n",
                "    value: str\n",
                "    lang: Literal['zh', 'en', 'num', 'other']\n",
                "    is_word_start: bool = False\n",
                "    is_word_end: bool = False\n",
                "    char_start: int = 0\n",
                "    char_end: int = 0\n",
                "\n",
                "    @property\n",
                "    def is_tone(self) -> bool:\n",
                "        return self.value.isdigit()\n",
                "\n",
                "    @property\n",
                "    def info(self) -> Tuple[str, str, bool, bool, bool, int, int]:\n",
                "        return (self.value, self.lang, self.is_word_start, self.is_word_end, self.is_tone, self.char_start, self.char_end)\n",
                "\n",
                "def normalize_text(text: str) -> str:\n",
                "    \"\"\"文本预处理：驼峰拆分、数字边界拆分、统一小写\"\"\"\n",
                "    result = []\n",
                "    prev_char = ''\n",
                "    for char in text:\n",
                "        if char.isalnum() or '\\u4e00' <= char <= '\\u9fff':\n",
                "            if char.isupper() and prev_char.islower():\n",
                "                result.append(' ')\n",
                "            elif char.isdigit() and prev_char.isalpha():\n",
                "                result.append(' ')\n",
                "            elif char.isalpha() and prev_char.isdigit():\n",
                "                result.append(' ')\n",
                "            result.append(char.lower())\n",
                "            prev_char = char\n",
                "        else:\n",
                "            if result and result[-1] != ' ':\n",
                "                result.append(' ')\n",
                "            prev_char = ''\n",
                "    return ''.join(result).strip()\n",
                "\n",
                "def split_mixed_label(input_str: str) -> List[str]:\n",
                "    \"\"\"将混合字符串切分为 token 列表\"\"\"\n",
                "    tokens = []\n",
                "    s = input_str.lower()\n",
                "    while len(s) > 0:\n",
                "        if s[0] == ' ':\n",
                "            s = s[1:]; continue\n",
                "        match = re.match(r'[a-z]+', s)\n",
                "        if match:\n",
                "            tokens.append(match.group(0)); s = s[len(match.group(0)):]; continue\n",
                "        match = re.match(r'[0-9]+', s)\n",
                "        if match:\n",
                "            tokens.append(match.group(0)); s = s[len(match.group(0)):]; continue\n",
                "        tokens.append(s[0]); s = s[1:]\n",
                "    return tokens\n",
                "\n",
                "def get_phoneme_info(text: str, ascii_split_char: bool = True) -> List[Phoneme]:\n",
                "    \"\"\"获取带位置和详细属性的音素序列\"\"\"\n",
                "    if not HAS_PYPINYIN:\n",
                "        return [Phoneme(c, 'zh', is_word_start=True, is_word_end=True, char_start=i, char_end=i+1) for i, c in enumerate(text)]\n",
                "\n",
                "    phoneme_seq: List[Phoneme] = []\n",
                "    pos = 0\n",
                "    while pos < len(text):\n",
                "        char = text[pos]\n",
                "        if '\\u4e00' <= char <= '\\u9fff':\n",
                "            start = pos\n",
                "            scan = pos + 1\n",
                "            while scan < len(text) and '\\u4e00' <= text[scan] <= '\\u9fff': scan += 1\n",
                "            frag = text[start:scan]\n",
                "            try:\n",
                "                py_inits = pinyin(frag, style=Style.INITIALS, strict=False, errors='ignore')\n",
                "                py_fins = pinyin(frag, style=Style.FINALS, strict=False, errors='ignore')\n",
                "                py_tones = pinyin(frag, style=Style.TONE3, neutral_tone_with_five=True, errors='ignore')\n",
                "                for i in range(min(len(frag), len(py_inits), len(py_fins), len(py_tones))):\n",
                "                    idx = start + i\n",
                "                    init, fin, tone = py_inits[i][0], py_fins[i][0], py_tones[i][0]\n",
                "                    if init: phoneme_seq.append(Phoneme(init, 'zh', is_word_start=True, char_start=idx, char_end=idx+1))\n",
                "                    if fin: phoneme_seq.append(Phoneme(fin, 'zh', is_word_start=not init, char_start=idx, char_end=idx+1))\n",
                "                    if tone and tone[-1].isdigit(): phoneme_seq.append(Phoneme(tone[-1], 'zh', is_word_end=True, char_start=idx, char_end=idx+1))\n",
                "            except:\n",
                "                for i, c in enumerate(frag): phoneme_seq.append(Phoneme(c, 'zh', is_word_start=True, is_word_end=True, char_start=start+i, char_end=start+i+1))\n",
                "            pos = scan\n",
                "        elif char.isalnum():\n",
                "            start = pos\n",
                "            while pos < len(text) and text[pos].isalnum():\n",
                "                if pos > start:\n",
                "                    p, c = text[pos-1], text[pos]\n",
                "                    if (p.islower() and c.isupper()) or (p.isalpha() and c.isdigit()) or (p.isdigit() and c.isalpha()): break\n",
                "                pos += 1\n",
                "            token = text[start:pos].lower()\n",
                "            lang = 'num' if token.isdigit() else 'en'\n",
                "            if ascii_split_char:\n",
                "                for i, c in enumerate(token): phoneme_seq.append(Phoneme(c, lang, is_word_start=(i==0), is_word_end=(i==len(token)-1), char_start=start+i, char_end=start+i+1))\n",
                "            else:\n",
                "                phoneme_seq.append(Phoneme(token, lang, is_word_start=True, is_word_end=True, char_start=start, char_end=pos))\n",
                "        else:\n",
                "            pos += 1\n",
                "    return phoneme_seq\n",
                "\n",
                "def get_phoneme_seq(text: str) -> List[Phoneme]:\n",
                "    \"\"\"简单音素序列获取，不包含详细位置信息\"\"\"\n",
                "    normalized = normalize_text(text)\n",
                "    if not HAS_PYPINYIN:\n",
                "        return [Phoneme(c, 'zh', is_word_start=True, is_word_end=True) for c in normalized.split()]\n",
                "    \n",
                "    seq = []\n",
                "    for token in split_mixed_label(normalized):\n",
                "        if re.match(r'^[a-z0-9]+$', token):\n",
                "            seq.append(Phoneme(token, 'num' if token.isdigit() else 'en', is_word_start=True, is_word_end=True))\n",
                "        elif len(token) == 1:\n",
                "            try:\n",
                "                py_t3 = pinyin(token, style=Style.TONE3, strict=False)\n",
                "                if not py_t3: seq.append(Phoneme(token, 'zh', is_word_start=True, is_word_end=True)); continue\n",
                "                init = pinyin(token, style=Style.INITIALS, strict=False)[0][0]\n",
                "                fin = pinyin(token, style=Style.FINALS, strict=False)[0][0]\n",
                "                tone = py_t3[0][0][-1] if py_t3[0][0][-1].isdigit() else '0'\n",
                "                if init: seq.append(Phoneme(init, 'zh', is_word_start=True))\n",
                "                if fin: seq.append(Phoneme(fin, 'zh', is_word_start=not init))\n",
                "                seq.append(Phoneme(tone, 'zh', is_word_end=True))\n",
                "            except:\n",
                "                seq.append(Phoneme(token, 'zh', is_word_start=True, is_word_end=True))\n",
                "    return seq"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 2. 相似度与检索算法\n",
                "包含模糊子串匹配得分以及 FastRAG 高性能粗筛模块。"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 3,
            "metadata": {},
            "outputs": [],
            "source": [
                "SIMILAR_PHONEMES = [{'an','ang'},{'en','eng'},{'in','ing'},{'ian','iang'},{'uan','uang'},{'z','zh'},{'c','ch'},{'s','sh'},{'l','n'},{'f','h'},{'ai','ei'}]\n",
                "\n",
                "def _get_tuple_cost(t1: Tuple, t2: Tuple) -> float:\n",
                "    if t1[1] != t2[1]: return 1.0\n",
                "    if t1[0] == t2[0]: return 0.0\n",
                "    if t1[1] == 'zh':\n",
                "        pair = {t1[0], t2[0]}\n",
                "        for s in SIMILAR_PHONEMES:\n",
                "            if pair.issubset(s): return 0.5\n",
                "    if t1[1] == 'en':\n",
                "        m, n = len(t1[0]), len(t2[0])\n",
                "        if m == 0 or n == 0: return 1.0\n",
                "        dp_prev, dp_curr = [0]*(n+1), [0]*(n+1)\n",
                "        for i in range(1, m+1):\n",
                "            for j in range(1, n+1):\n",
                "                dp_curr[j] = dp_prev[j-1]+1 if t1[0][i-1]==t2[0][j-1] else max(dp_prev[j], dp_curr[j-1])\n",
                "            dp_prev, dp_curr = dp_curr, dp_prev\n",
                "        return 1.0 - (dp_prev[n] / max(m, n))\n",
                "    return 1.0\n",
                "\n",
                "def fuzzy_substring_distance(hw_info: List[Tuple], input_info: List[Tuple]) -> float:\n",
                "    n, m = len(hw_info), len(input_info)\n",
                "    if n == 0: return 0.0\n",
                "    if m == 0: return float(n)\n",
                "    prev, curr = [0.0]*(m+1), [0.0]*(m+1)\n",
                "    for i in range(1, n+1):\n",
                "        curr[0] = float(i)\n",
                "        for j in range(1, m+1):\n",
                "            cost = _get_tuple_cost(hw_info[i-1], input_info[j-1])\n",
                "            curr[j] = min(prev[j]+1.0, curr[j-1]+1.0, prev[j-1]+cost)\n",
                "        prev, curr = curr, prev\n",
                "    return min(prev)\n",
                "\n",
                "def fuzzy_substring_score(hw_info: List[Tuple], input_info: List[Tuple]) -> float:\n",
                "    n = len(hw_info)\n",
                "    if n == 0: return 0.0\n",
                "    dist = fuzzy_substring_distance(hw_info, input_info)\n",
                "    return max(0.0, 1.0 - (dist / n))\n",
                "\n",
                "if HAS_NUMBA:\n",
                "    @njit(cache=True)\n",
                "    def _fuzzy_substring_distance_numba(main_codes: np.ndarray, sub_codes: np.ndarray) -> float:\n",
                "        n, m = len(sub_codes), len(main_codes)\n",
                "        if n == 0 or m == 0: return float(n)\n",
                "        dp = np.zeros((n + 1, m + 1), dtype=np.float32)\n",
                "        for i in range(1, n + 1): dp[i, 0] = float(i)\n",
                "        for i in range(1, n + 1):\n",
                "            for j in range(1, m + 1):\n",
                "                cost = 0.0 if sub_codes[i-1] == main_codes[j-1] else 1.0\n",
                "                dp[i, j] = min(dp[i-1, j] + 1.0, dp[i, j-1] + 1.0, dp[i-1, j-1] + cost)\n",
                "        min_dist = dp[n, 1]\n",
                "        for j in range(2, m + 1): \n",
                "            if dp[n, j] < min_dist: min_dist = dp[n, j]\n",
                "        return min_dist\n",
                "\n",
                "class PhonemeEncoder:\n",
                "    def __init__(self): self.p2c = {}; self.next = 1\n",
                "    def encode(self, p: str):\n",
                "        if p not in self.p2c: self.p2c[p] = self.next; self.next += 1\n",
                "        return self.p2c[p]\n",
                "    def encode_seq(self, ps: List[str]):\n",
                "        if not HAS_NUMBA: return [self.encode(p) for p in ps]\n",
                "        return np.array([self.encode(p) for p in ps], dtype=np.int32)\n",
                "\n",
                "class FastRAG:\n",
                "    def __init__(self, threshold: float = 0.6):\n",
                "        self.threshold = threshold\n",
                "        self.encoder = PhonemeEncoder()\n",
                "        self.index = defaultdict(list)\n",
                "        self.hotword_count = 0\n",
                "    def add_hotwords(self, hotwords: Dict[str, List[Phoneme]]):\n",
                "        for hw, phons in hotwords.items():\n",
                "            if not phons: continue\n",
                "            codes = self.encoder.encode_seq([p.value for p in phons])\n",
                "            idx_pos = [0]\n",
                "            if phons[0].lang == 'en': idx_pos = list(range(min(len(phons), 2)))\n",
                "            for p in {codes[i] for i in idx_pos if i < len(codes)}:\n",
                "                self.index[p].append((hw, codes))\n",
                "            self.hotword_count += 1\n",
                "    def search(self, input_phons: List[Phoneme], top_k: int = 10) -> List[Tuple[str, float]]:\n",
                "        if not input_phons: return []\n",
                "        input_codes = self.encoder.encode_seq([p.value for p in input_phons])\n",
                "        input_p_set = set(input_codes)\n",
                "        candidates = []\n",
                "        seen = set()\n",
                "        for code in input_p_set:\n",
                "            if code in self.index:\n",
                "                for hw, codes in self.index[code]:\n",
                "                    if hw not in seen: candidates.append((hw, codes)); seen.add(hw)\n",
                "        results = []\n",
                "        input_len = len(input_codes)\n",
                "        for hw, hw_codes in candidates:\n",
                "            if len(hw_codes) > input_len + 3: continue\n",
                "            if HAS_NUMBA: dist = _fuzzy_substring_distance_numba(input_codes, hw_codes)\n",
                "            else:\n",
                "                ns, mm = len(hw_codes), len(input_codes)\n",
                "                dp = [[float(i) if j==0 else 0.0 for j in range(mm+1)] for i in range(ns+1)]\n",
                "                for i in range(1, ns+1):\n",
                "                    for j in range(1, mm+1):\n",
                "                        cost = 0.0 if hw_codes[i-1] == input_codes[j-1] else 1.0\n",
                "                        dp[i][j] = min(dp[i-1][j]+1.0, dp[i][j-1]+1.0, dp[i-1][j-1]+cost)\n",
                "                dist = min(dp[ns][1:])\n",
                "            score = 1.0 - (dist / len(hw_codes))\n",
                "            if score >= self.threshold: results.append((hw, round(score, 3)))\n",
                "        results.sort(key=lambda x: x[1], reverse=True)\n",
                "        return results[:top_k]"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 3. 纠错组件\n",
                "包含 `PhonemeCorrector`, `RuleCorrector` 和 `RectificationRAG` 三个主要纠错类。"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 4,
            "metadata": {},
            "outputs": [],
            "source": [
                "class MatchResult(NamedTuple):\n",
                "    start: int; end: int; score: float; hotword: str\n",
                "\n",
                "class CorrectionResult(NamedTuple):\n",
                "    text: str; matchs: List[Tuple[str, float]]; similars: List[Tuple[str, float]]\n",
                "\n",
                "class PhonemeCorrector:\n",
                "    def __init__(self, threshold: float = 0.7):\n",
                "        self.threshold = threshold\n",
                "        self.similar_threshold = threshold - 0.2\n",
                "        self.hotwords: Dict[str, List[Phoneme]] = {}\n",
                "        self.fast_rag = FastRAG(threshold=self.similar_threshold - 0.1)\n",
                "        self._lock = threading.Lock()\n",
                "\n",
                "    def update_hotwords(self, hotword_text: str) -> int:\n",
                "        lines = [l.strip() for l in hotword_text.splitlines() if l.strip() and not l.strip().startswith('#')]\n",
                "        new_hotwords = {}\n",
                "        for hw in lines:\n",
                "            phons = get_phoneme_info(hw)\n",
                "            if phons: new_hotwords[hw] = phons\n",
                "        with self._lock:\n",
                "            self.hotwords = new_hotwords\n",
                "            self.fast_rag = FastRAG(threshold=self.similar_threshold - 0.1)\n",
                "            self.fast_rag.add_hotwords(new_hotwords)\n",
                "        return len(new_hotwords)\n",
                "\n",
                "    def correct(self, text: str) -> CorrectionResult:\n",
                "        if not text or not self.hotwords: return CorrectionResult(text, [], [])\n",
                "        input_phons = get_phoneme_info(text)\n",
                "        if not input_phons: return CorrectionResult(text, [], [])\n",
                "        with self._lock:\n",
                "            fast_results = self.fast_rag.search(input_phons, top_k=100)\n",
                "            input_processed = [p.info for p in input_phons]\n",
                "            matches = []; similars = []; input_len = len(input_processed)\n",
                "            for hw, _ in fast_results:\n",
                "                hw_phons = self.hotwords[hw]\n",
                "                hw_compare = [p.info[:5] for p in hw_phons]\n",
                "                target_len = len(hw_compare)\n",
                "                if target_len > input_len: continue\n",
                "                for i in range(input_len - target_len + 1):\n",
                "                    sub_seg = input_processed[i : i + target_len]\n",
                "                    if sub_seg[0][1] != 'en' and sub_seg[0][0] != hw_compare[0][0]: continue\n",
                "                    if not sub_seg[0][2]: continue\n",
                "                    is_end_ok = sub_seg[-1][3] or (i+target_len < input_len and input_processed[i+target_len][1]=='zh' and input_processed[i+target_len][4] and input_processed[i+target_len][3])\n",
                "                    if not is_end_ok: continue\n",
                "                    score = fuzzy_substring_score(hw_compare, sub_seg)\n",
                "                    char_start, char_end = sub_seg[0][5], sub_seg[-1][6]\n",
                "                    similars.append(MatchResult(char_start, char_end, score, hw))\n",
                "                    if score >= self.threshold: matches.append(MatchResult(char_start, char_end, score, hw))\n",
                "        similars.sort(key=lambda x: x.score, reverse=True)\n",
                "        seen_sim = set(); top_sim = []\n",
                "        for s in similars:\n",
                "            if s.hotword not in seen_sim: top_sim.append((s.hotword, s.score)); seen_sim.add(s.hotword)\n",
                "        matches.sort(key=lambda x: (x.score, x.end - x.start), reverse=True)\n",
                "        final_matches = []; occupied = []\n",
                "        for m in matches:\n",
                "            if any(not (m.end <= rs or m.start >= re) for rs, re in occupied): continue\n",
                "            if text[m.start:m.end] != m.hotword: final_matches.append(m)\n",
                "            occupied.append((m.start, m.end))\n",
                "        final_matches.sort(key=lambda x: x.start, reverse=True)\n",
                "        res_list = list(text)\n",
                "        for m in final_matches: res_list[m.start : m.end] = list(m.hotword)\n",
                "        return CorrectionResult(\"\".join(res_list), [(m.hotword, m.score) for m in final_matches], top_sim[:5])\n",
                "\n",
                "class RuleCorrector:\n",
                "    def __init__(self): self.patterns: Dict[str, str] = {}; self._lock = threading.Lock()\n",
                "    def update_rules(self, rule_text: str) -> int:\n",
                "        new_patterns = {}\n",
                "        for line in rule_text.splitlines():\n",
                "            line = line.strip()\n",
                "            if not line or line.startswith('#'): continue\n",
                "            parts = line.split('=')\n",
                "            if len(parts) == 2: new_patterns[parts[0].strip()] = parts[1].strip()\n",
                "        with self._lock: self.patterns = new_patterns\n",
                "        return len(new_patterns)\n",
                "    def substitute(self, text: str) -> str:\n",
                "        if not text or not self.patterns: return text\n",
                "        with self._lock: patterns = self.patterns.copy()\n",
                "        result = text\n",
                "        for p, r in patterns.items():\n",
                "            try: result = re.sub(p, r, result)\n",
                "            except: pass\n",
                "        return result\n",
                "\n",
                "@dataclass\n",
                "class RectifyRecord:\n",
                "    wrong: str; right: str; fragments: List[str]; frag_phons: Dict[str, List[Phoneme]]\n",
                "\n",
                "class RectificationRAG:\n",
                "    def __init__(self, threshold: float = 0.5):\n",
                "        self.threshold = threshold\n",
                "        self.records: List[RectifyRecord] = []; self._lock = threading.Lock()\n",
                "    def load_rectify_text(self, text: str):\n",
                "        new_records = []\n",
                "        for block in text.split('---'):\n",
                "            lines = [l.strip() for l in block.splitlines() if l.strip() and not l.strip().startswith('#')]\n",
                "            if len(lines) >= 2:\n",
                "                wrong, right = lines[0], lines[1]\n",
                "                w_b = self._get_word_bounds(wrong); r_b = self._get_word_bounds(right)\n",
                "                sm = SequenceMatcher(None, [b[2] for b in w_b], [b[2] for b in r_b])\n",
                "                frags = []\n",
                "                for tag, i1, i2, j1, j2 in sm.get_opcodes():\n",
                "                    if tag in ('replace', 'delete') and i2 > i1: frags.append(wrong[w_b[i1][0] : w_b[i2-1][1]])\n",
                "                    if tag in ('replace', 'insert') and j2 > j1: frags.append(right[r_b[j1][0] : r_b[j2-1][1]])\n",
                "                if not frags: frags = [wrong]\n",
                "                frags = list(dict.fromkeys(frags))\n",
                "                frag_phons = {f: get_phoneme_seq(f) for f in frags}\n",
                "                new_records.append(RectifyRecord(wrong, right, frags, frag_phons))\n",
                "        with self._lock: self.records = new_records\n",
                "    def _get_word_bounds(self, text: str):\n",
                "        bounds = []; i = 0; n = len(text)\n",
                "        while i < n:\n",
                "            if not (text[i].isalnum() or '\\u4e00' <= text[i] <= '\\u9fff'): i += 1; continue\n",
                "            s = i\n",
                "            if '\\u4e00' <= text[i] <= '\\u9fff': i += 1\n",
                "            else:\n",
                "                while i < n and text[i].isalnum():\n",
                "                    if i > s and text[i].isupper() and text[i-1].islower(): break\n",
                "                    i += 1\n",
                "            bounds.append((s, i, text[s:i]))\n",
                "        return bounds\n",
                "    def search(self, text: str, top_k: int = 5) -> List[Tuple[str, str, float]]:\n",
                "        if not text or not self.records: return []\n",
                "        input_phons = [p.info for p in get_phoneme_seq(text)]\n",
                "        if not input_phons: return []\n",
                "        results = []\n",
                "        with self._lock:\n",
                "            for rec in self.records:\n",
                "                score = 0.0\n",
                "                for f_phon in rec.frag_phons.values():\n",
                "                    if not f_phon: continue\n",
                "                    score = max(score, fuzzy_substring_score([p.info for p in f_phon], input_phons))\n",
                "                if score >= self.threshold: results.append((rec.wrong, rec.right, round(score, 3)))\n",
                "        results.sort(key=lambda x: x[2], reverse=True)\n",
                "        return results[:top_k]"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 4. 综合演示\n",
                "准备演示数据并执行纠错测试。"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 5,
            "metadata": {},
            "outputs": [],
            "source": [
                "# --- A. 数据准备 ---\n",
                "\n",
                "hotwords_data = \"\"\"\n",
                "    Claude\n",
                "    Bilibili\n",
                "    Microsoft\n",
                "    买当劳\n",
                "    肯德基\n",
                "    # 这是一个注释\n",
                "    VsCode\n",
                "    VsCodes\n",
                "\"\"\"\n",
                "    \n",
                "rectify_data = \"\"\"\n",
                "# 纠错历史演示\n",
                "把那个锯子给我\n",
                "把那个句子给我\n",
                "---\n",
                "cloud code is good\n",
                "Claude Code is good\n",
                "---\n",
                "今天天其不错\n",
                "今天天气不错\n",
                "\"\"\"\n",
                "\n",
                "\n",
                "test_cases_text = \"\"\"\n",
                "我想去吃买当劳和肯得鸡\n",
                "Hello klaude\n",
                "喜欢刷Bili Bili\n",
                "请把那个锯子发给我一下\n",
                "今天天及真的很好\n",
                "I think klaud code is very good\n",
                "\"\"\"\n",
                "cases = [l.strip() for l in test_cases_text.strip().split('\\n') if l.strip()]"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 6,
            "metadata": {},
            "outputs": [],
            "source": [
                "# --- B. 系统初始化与数据加载 ---\n",
                "\n",
                "# 初始化纠错器和检索器\n",
                "corrector = PhonemeCorrector(threshold=0.8)\n",
                "rectifier = RectificationRAG(threshold=0.5)\n",
                "\n",
                "# 从字符串加载热词\n",
                "corrector.update_hotwords(hotwords_data)\n",
                "rectifier.load_rectify_text(rectify_data)\n",
                "\n",
                "# 从文本文件加载热词\n",
                "# corrector.load_hotwords_file(\"hot.txt\")\n",
                "# rectifier.load_rectify_file(\"hot-rectify.txt\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 7,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "\n",
                        "==================================================\n",
                        "【 CapsWriter-Offline 综合纠错系统演示 】\n",
                        "==================================================\n",
                        "\n",
                        "Case 1: '我想去吃买当劳和肯得鸡'\n",
                        "  [纠错结果] 我想去吃买当劳和肯德基\n",
                        "  [匹配热词] [('肯德基', 1.0)]\n",
                        "  [相似推荐] [('买当劳', 1.0), ('肯德基', 1.0)]\n",
                        "  [RAG 相似历史]\n",
                        "    - '把那个锯子给我' => '把那个句子给我' (相似度: 0.667)\n",
                        "    - '今天天其不错' => '今天天气不错' (相似度: 0.667)\n",
                        "\n",
                        "Case 2: 'Hello klaude'\n",
                        "  [纠错结果] Hello Claude\n",
                        "  [匹配热词] [('Claude', 0.8333333333333334)]\n",
                        "  [相似推荐] [('Claude', 0.8333333333333334)]\n",
                        "\n",
                        "Case 3: '喜欢刷Bili Bili'\n",
                        "  [纠错结果] 喜欢刷Bilibili\n",
                        "  [匹配热词] [('Bilibili', 1.0)]\n",
                        "  [相似推荐] [('Bilibili', 1.0)]\n",
                        "\n",
                        "Case 4: '请把那个锯子发给我一下'\n",
                        "  [纠错结果] 请把那个锯子发给我一下\n",
                        "  [RAG 相似历史]\n",
                        "    - '把那个锯子给我' => '把那个句子给我' (相似度: 1.000)\n",
                        "\n",
                        "Case 5: '今天天及真的很好'\n",
                        "  [纠错结果] 今天天及真的很好\n",
                        "  [RAG 相似历史]\n",
                        "    - '今天天其不错' => '今天天气不错' (相似度: 0.667)\n",
                        "\n",
                        "Case 6: 'I think klaud code is very good'\n",
                        "  [纠错结果] I think klaud code is very good\n",
                        "  [相似推荐] [('VsCode', 0.6666666666666667), ('Claude', 0.5)]\n",
                        "  [RAG 相似历史]\n",
                        "    - 'cloud code is good' => 'Claude Code is good' (相似度: 0.833)\n"
                    ]
                }
            ],
            "source": [
                "# --- C. 执行综合纠错演示 ---\n",
                "print(\"\\n\" + \"=\"*50)\n",
                "print(\"【 CapsWriter-Offline 综合纠错系统演示 】\")\n",
                "print(\"=\"*50)\n",
                "\n",
                "for i, t in enumerate(cases):\n",
                "    print(f\"\\nCase {i+1}: '{t}'\")\n",
                "    res, matched, similars = corrector.correct(t)\n",
                "    print(f\"  [纠错结果] {res}\")\n",
                "    if matched: print(f\"  [匹配热词] {matched}\")\n",
                "    if similars: print(f\"  [相似推荐] {similars}\")\n",
                "    rag_results = rectifier.search(t)\n",
                "    if rag_results:\n",
                "        print(f\"  [RAG 相似历史]\")\n",
                "        for wrong, right, score in rag_results:\n",
                "            print(f\"    - '{wrong}' => '{right}' (相似度: {score:.3f})\")"
            ]
        }
    ],
    "metadata": {
        "kernelspec": {
            "display_name": "capswriter",
            "language": "python",
            "name": "python3"
        },
        "language_info": {
            "codemirror_mode": {
                "name": "ipython",
                "version": 3
            },
            "file_extension": ".py",
            "mimetype": "text/x-python",
            "name": "python",
            "nbconvert_exporter": "python",
            "pygments_lexer": "ipython3",
            "version": "3.10.19"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 4
}
