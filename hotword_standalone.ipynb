{
    "cells": [
        {
            "cell_type": "markdown",
            "id": "4cc769c5",
            "metadata": {},
            "source": [
                "# CapsWriter-Offline 独立热词与纠错系统 (Portable Standalone)\n",
                "\n",
                "本 Notebook 完整整合了以下核心逻辑，**逻辑分支与原始代码库完全对等**：\n",
                "- **音素处理** (algo_phoneme)\n",
                "- **相似度算法** (algo_calc)\n",
                "- **FastRAG 加速检索** (rag_fast)\n",
                "- **拼音纠错** (PhonemeCorrector, 包含 `similar_threshold` 相关逻辑)\n",
                "- **纠错历史 RAG** (RectificationRAG)\n",
                "- **调试工具** (Phoneme Debug)\n",
                "- **LLM 集成** (Prompt Builder & Ollama Client)\n",
                "\n",
                "数据准备和输出方式参照自 `hotword_system_demo.ipynb`。"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 1,
            "id": "a55132cd",
            "metadata": {},
            "outputs": [],
            "source": [
                "import sys\n",
                "import os\n",
                "import re\n",
                "import time\n",
                "import json\n",
                "import requests\n",
                "import threading\n",
                "import logging\n",
                "from typing import List, Tuple, Dict, Set, Union, Literal, Optional, NamedTuple\n",
                "from dataclasses import dataclass\n",
                "from collections import defaultdict\n",
                "from difflib import SequenceMatcher\n",
                "from pathlib import Path\n",
                "\n",
                "# 配置日志\n",
                "logging.basicConfig(level=logging.INFO, format='%(message)s')\n",
                "logger = logging.getLogger(__name__)\n",
                "\n",
                "# 确保控制台输出 UTF-8\n",
                "if sys.platform == 'win32':\n",
                "    if hasattr(sys.stdout, 'reconfigure'):\n",
                "        sys.stdout.reconfigure(encoding='utf-8')\n",
                "\n",
                "# --- 依赖库导入 ---\n",
                "try:\n",
                "    from pypinyin import pinyin, Style\n",
                "except ImportError:\n",
                "    pinyin = None; Style = None\n",
                "\n",
                "try:\n",
                "    import numpy as np\n",
                "    HAS_NUMPY = True\n",
                "except ImportError:\n",
                "    HAS_NUMPY = False\n",
                "\n",
                "try:\n",
                "    from numba import njit\n",
                "    HAS_NUMBA = True\n",
                "except ImportError:\n",
                "    HAS_NUMBA = False"
            ]
        },
        {
            "cell_type": "markdown",
            "id": "f170e4d3",
            "metadata": {},
            "source": [
                "## 1. 核心模型与音素处理 (algo_phoneme)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 2,
            "id": "37550be0",
            "metadata": {},
            "outputs": [],
            "source": [
                "@dataclass(frozen=True, slots=True)\n",
                "class Phoneme:\n",
                "    value: str\n",
                "    lang: Literal['zh', 'en', 'num', 'other']\n",
                "    is_word_start: bool = False\n",
                "    is_word_end: bool = False\n",
                "    char_start: int = 0\n",
                "    char_end: int = 0\n",
                "\n",
                "    @property\n",
                "    def is_tone(self) -> bool: return self.value.isdigit()\n",
                "    @property\n",
                "    def info(self) -> Tuple[str, str, bool, bool, bool, int, int]:\n",
                "        return (self.value, self.lang, self.is_word_start, self.is_word_end, self.is_tone, self.char_start, self.char_end)\n",
                "\n",
                "def normalize_text(text: str) -> str:\n",
                "    res = []; prev = ''\n",
                "    for c in text:\n",
                "        if c.isalnum() or '\\u4e00' <= c <= '\\u9fff':\n",
                "            if c.isupper() and prev.islower(): res.append(' ')\n",
                "            elif c.isdigit() and prev.isalpha(): res.append(' ')\n",
                "            elif prev.isdigit() and c.isalpha(): res.append(' ')\n",
                "            res.append(c.lower()); prev = c\n",
                "        else:\n",
                "            if res and res[-1] != ' ': res.append(' ')\n",
                "            prev = ''\n",
                "    return \"\".join(res).strip()\n",
                "\n",
                "def split_mixed_label(text: str) -> List[str]:\n",
                "    tokens = []; s = text.lower()\n",
                "    while s:\n",
                "        if s[0] == ' ': s = s[1:]; continue\n",
                "        m = re.match(r'[a-z]+', s)\n",
                "        if m: tokens.append(m.group(0)); s = s[len(m.group(0)):]\n",
                "        else:\n",
                "            m = re.match(r'[0-9]+', s)\n",
                "            if m: tokens.append(m.group(0)); s = s[len(m.group(0)):]\n",
                "            else: tokens.append(s[0]); s = s[1:]\n",
                "    return tokens\n",
                "\n",
                "def get_phoneme_info(text: str, split_char: bool = True) -> List[Phoneme]:\n",
                "    if not pinyin: return [Phoneme(c, 'zh', char_start=i, char_end=i+1) for i, c in enumerate(text)]\n",
                "    seq = []; pos = 0\n",
                "    while pos < len(text):\n",
                "        c = text[pos]\n",
                "        if '\\u4e00' <= c <= '\\u9fff':\n",
                "            start = pos; pos += 1\n",
                "            while pos < len(text) and '\\u4e00' <= text[pos] <= '\\u9fff': pos += 1\n",
                "            frag = text[start:pos]\n",
                "            try:\n",
                "                pi = pinyin(frag, style=Style.INITIALS, strict=False)\n",
                "                pf = pinyin(frag, style=Style.FINALS, strict=False)\n",
                "                pt = pinyin(frag, style=Style.TONE3, neutral_tone_with_five=True)\n",
                "                for i in range(min(len(frag), len(pi), len(pf), len(pt))):\n",
                "                    idx = start + i; init, fin, tone = pi[i][0], pf[i][0], pt[i][0]\n",
                "                    if init: seq.append(Phoneme(init, 'zh', is_word_start=True, char_start=idx, char_end=idx+1))\n",
                "                    if fin: seq.append(Phoneme(fin, 'zh', is_word_start=not init, char_start=idx, char_end=idx+1))\n",
                "                    if tone and tone[-1].isdigit(): seq.append(Phoneme(tone[-1], 'zh', is_word_end=True, char_start=idx, char_end=idx+1))\n",
                "            except: \n",
                "                for i, char in enumerate(frag): seq.append(Phoneme(char, 'zh', is_word_start=True, is_word_end=True, char_start=start+i, char_end=start+i+1))\n",
                "        elif 'a' <= c.lower() <= 'z' or '0' <= c <= '9':\n",
                "            start = pos; pos += 1\n",
                "            while pos < len(text):\n",
                "                cur = text[pos]\n",
                "                if not ('a' <= cur.lower() <= 'z' or '0' <= cur <= '9'): break\n",
                "                if (text[pos-1].islower() and cur.isupper()) or (text[pos-1].isalpha() and cur.isdigit()) or (text[pos-1].isdigit() and cur.isalpha()): break\n",
                "                pos += 1\n",
                "            token = text[start:pos].lower(); lang = 'num' if token.isdigit() else 'en'\n",
                "            if split_char:\n",
                "                for i, char in enumerate(token): seq.append(Phoneme(char, lang, is_word_start=(i==0), is_word_end=(i==len(token)-1), char_start=start+i, char_end=start+i+1))\n",
                "            else: seq.append(Phoneme(token, lang, is_word_start=True, is_word_end=True, char_start=start, char_end=pos))\n",
                "        else: pos += 1\n",
                "    return seq\n",
                "\n",
                "def get_phoneme_seq(text: str) -> List[Phoneme]:\n",
                "    normalized = normalize_text(text)\n",
                "    seq = []\n",
                "    for token in split_mixed_label(normalized):\n",
                "        if re.match(r'^[a-z0-9]+$', token):\n",
                "            lang = 'num' if token.isdigit() else 'en'\n",
                "            seq.append(Phoneme(token, lang, is_word_start=True, is_word_end=True))\n",
                "        elif len(token) == 1:\n",
                "            if not pinyin: seq.append(Phoneme(token, 'zh', is_word_start=True, is_word_end=True))\n",
                "            else:\n",
                "                try:\n",
                "                    pi = pinyin(token, style=Style.INITIALS, strict=False)\n",
                "                    pf = pinyin(token, style=Style.FINALS, strict=False)\n",
                "                    pt = pinyin(token, style=Style.TONE3, neutral_tone_with_five=True)\n",
                "                    has_init = pi and pi[0] and pi[0][0]\n",
                "                    if has_init: seq.append(Phoneme(pi[0][0], 'zh', is_word_start=True))\n",
                "                    if pf and pf[0] and pf[0][0]: seq.append(Phoneme(pf[0][0], 'zh', is_word_start=not has_init))\n",
                "                    tone = pt[0][0][-1] if pt[0][0][-1].isdigit() else '5'\n",
                "                    seq.append(Phoneme(tone, 'zh', is_word_end=True))\n",
                "                except: seq.append(Phoneme(token, 'zh', is_word_start=True, is_word_end=True))\n",
                "        else: seq.append(Phoneme(token, 'zh', is_word_start=True, is_word_end=True))\n",
                "    return seq"
            ]
        },
        {
            "cell_type": "markdown",
            "id": "17e3c575",
            "metadata": {},
            "source": [
                "## 2. 相似度算法 (algo_calc)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 3,
            "id": "2c4b31e5",
            "metadata": {},
            "outputs": [],
            "source": [
                "SIMILAR_PHONEMES = [{'an', 'ang'}, {'en', 'eng'}, {'in', 'ing'}, {'ian', 'iang'}, {'uan', 'uang'}, {'z', 'zh'}, {'c', 'ch'}, {'s', 'sh'}, {'l', 'n'}, {'f', 'h'}, {'ai', 'ei'}]\n",
                "\n",
                "def _lcs_length(s1: str, s2: str) -> int:\n",
                "    m, n = len(s1), len(s2)\n",
                "    if m < n: s1, s2 = s2, s1; m, n = n, m\n",
                "    if n == 0: return 0\n",
                "    prev = [0] * (n + 1); curr = [0] * (n + 1)\n",
                "    for i in range(1, m + 1):\n",
                "        for j in range(1, n + 1):\n",
                "            curr[j] = prev[j-1] + 1 if s1[i-1] == s2[j-1] else max(prev[j], curr[j-1])\n",
                "        prev, curr = curr, prev\n",
                "    return prev[n]\n",
                "\n",
                "def _get_tuple_cost(t1: Tuple, t2: Tuple) -> float:\n",
                "    if t1[1] != t2[1]: return 1.0\n",
                "    if t1[0] == t2[0]: return 0.0\n",
                "    if t1[1] == 'zh':\n",
                "        pair = {t1[0], t2[0]}\n",
                "        for s in SIMILAR_PHONEMES:\n",
                "            if pair.issubset(s): return 0.5\n",
                "    if t1[1] == 'en':\n",
                "        lcs = _lcs_length(t1[0], t2[0])\n",
                "        max_len = max(len(t1[0]), len(t2[0]))\n",
                "        if max_len > 0: return 1.0 - (lcs / max_len)\n",
                "    return 1.0\n",
                "\n",
                "def fuzzy_substring_distance(seq1: Union[List[Phoneme], List[Tuple]], seq2: Union[List[Phoneme], List[Tuple]]) -> float:\n",
                "    n, m = len(seq1), len(seq2)\n",
                "    if n == 0: return 0.0\n",
                "    if m == 0: return float(n)\n",
                "    t1 = [p.info if isinstance(p, Phoneme) else p for p in seq1]\n",
                "    t2 = [p.info if isinstance(p, Phoneme) else p for p in seq2]\n",
                "    prev = [0.0] * (m + 1); curr = [0.0] * (m + 1)\n",
                "    for i in range(1, n + 1):\n",
                "        curr[0] = float(i)\n",
                "        for j in range(1, m + 1):\n",
                "            cost = _get_tuple_cost(t1[i-1], t2[j-1])\n",
                "            curr[j] = min(prev[j]+1.0, curr[j-1]+1.0, prev[j-1]+cost)\n",
                "        prev, curr = curr, prev\n",
                "    return min(prev)\n",
                "\n",
                "def fuzzy_substring_score(seq1, seq2) -> float:\n",
                "    n = len(seq1)\n",
                "    if n == 0: return 0.0\n",
                "    dist = fuzzy_substring_distance(seq1, seq2)\n",
                "    return max(0.0, 1.0 - (dist / n))"
            ]
        },
        {
            "cell_type": "markdown",
            "id": "55ee7e0b",
            "metadata": {},
            "source": [
                "## 3. RAG 加速检索与核心算法 (rag_fast)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 4,
            "id": "95cbd73d",
            "metadata": {},
            "outputs": [],
            "source": [
                "if HAS_NUMBA and HAS_NUMPY:\n",
                "    @njit(cache=True)\n",
                "    def _fuzzy_substring_numba(main, sub):\n",
                "        n, m = len(sub), len(main)\n",
                "        if n == 0 or m == 0: return float(n)\n",
                "        dp = np.zeros((n+1, m+1), dtype=np.float32)\n",
                "        for i in range(1, n+1): dp[i, 0] = float(i)\n",
                "        for i in range(1, n+1):\n",
                "            for j in range(1, m+1):\n",
                "                cost = 0.0 if sub[i-1] == main[j-1] else 1.0\n",
                "                dp[i, j] = min(dp[i-1, j]+1.0, dp[i, j-1]+1.0, dp[i-1, j-1]+cost)\n",
                "        return np.min(dp[n, 1:])\n",
                "\n",
                "class FastRAG:\n",
                "    def __init__(self, threshold=0.6):\n",
                "        self.threshold = threshold\n",
                "        self.ph_to_id = {}; self.index = defaultdict(list); self.hotword_count = 0\n",
                "    def _encode(self, phs: List[Phoneme]):\n",
                "        ids = []\n",
                "        for p in phs:\n",
                "            if p.value not in self.ph_to_id: self.ph_to_id[p.value] = len(self.ph_to_id) + 1\n",
                "            ids.append(self.ph_to_id[p.value])\n",
                "        return np.array(ids, dtype=np.int32) if HAS_NUMPY else ids\n",
                "    def add_hotwords(self, hotwords: Dict[str, List[Phoneme]]):\n",
                "        for hw, phs in hotwords.items():\n",
                "            if not phs: continue\n",
                "            codes = self._encode(phs)\n",
                "            for i in range(min(len(codes), 2)): self.index[codes[i]].append((hw, codes))\n",
                "            self.hotword_count += 1\n",
                "    def search(self, input_phs: List[Phoneme], top_k=10):\n",
                "        if not input_phs: return []\n",
                "        input_codes = self._encode(input_phs); unique = set(input_codes); candidates = []\n",
                "        for c in unique: candidates.extend(self.index.get(c, []))\n",
                "        seen = set(); results = []\n",
                "        for hw, cands in candidates:\n",
                "            if hw in seen or len(cands) > len(input_codes) + 3: continue\n",
                "            seen.add(hw)\n",
                "            if HAS_NUMBA and HAS_NUMPY: dist = _fuzzy_substring_numba(input_codes, cands)\n",
                "            else: dist = self._python_dist(input_codes, cands)\n",
                "            score = 1.0 - (dist / len(cands))\n",
                "            if score >= self.threshold: results.append((hw, round(float(score), 3)))\n",
                "        results.sort(key=lambda x: x[1], reverse=True)\n",
                "        return results[:top_k]\n",
                "    def _python_dist(self, main, sub):\n",
                "        n, m = len(sub), len(main)\n",
                "        dp = [[0.0] * (m+1) for _ in range(n+1)]\n",
                "        for i in range(1, n+1): dp[i][0] = float(i)\n",
                "        for i in range(1, n+1):\n",
                "            for j in range(1, m+1):\n",
                "                cost = 0.0 if sub[i-1] == main[j-1] else 1.0\n",
                "                dp[i][j] = min(dp[i-1, j]+1.0, dp[i, j-1]+1.0, dp[i-1, j-1]+cost)\n",
                "        return min(dp[n][1:])"
            ]
        },
        {
            "cell_type": "markdown",
            "id": "90111570",
            "metadata": {},
            "source": [
                "## 4. 纠错系统逻辑 (hot_phoneme & hot_rectification)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 5,
            "id": "470d32b3",
            "metadata": {},
            "outputs": [],
            "source": [
                "class MatchResult(NamedTuple):\n",
                "    start: int; end: int; score: float; hotword: str\n",
                "\n",
                "class CorrectionResult(NamedTuple):\n",
                "    text: str; matchs: List[Tuple[str, float]]; similars: List[Tuple[str, float]]\n",
                "\n",
                "class PhonemeCorrector:\n",
                "    def __init__(self, threshold: float = 0.7, similar_threshold: float = None):\n",
                "        self.threshold = threshold\n",
                "        self.similar_threshold = similar_threshold if similar_threshold is not None else threshold - 0.2\n",
                "        self.hotwords: Dict[str, List[Phoneme]] = {}\n",
                "        self.fast_rag = FastRAG(threshold=min(self.threshold, self.similar_threshold) - 0.1)\n",
                "        self._lock = threading.Lock()\n",
                "    def update_hotwords(self, text: str):\n",
                "        lines = [l.strip() for l in text.splitlines() if l.strip() and not l.strip().startswith('#')]\n",
                "        new_hotwords = {}\n",
                "        for hw in lines:\n",
                "            phs = get_phoneme_info(hw)\n",
                "            if phs: new_hotwords[hw] = phs\n",
                "        with self._lock:\n",
                "            self.hotwords = new_hotwords\n",
                "            self.fast_rag = FastRAG(threshold=min(self.threshold, self.similar_threshold) - 0.1)\n",
                "            self.fast_rag.add_hotwords(new_hotwords)\n",
                "        return len(new_hotwords)\n",
                "    def load_hotwords_file(self, path: str):\n",
                "        if os.path.exists(path):\n",
                "            with open(path, 'r', encoding='utf-8') as f: return self.update_hotwords(f.read())\n",
                "        return 0\n",
                "    def _find_matches(self, fast_results, input_processed):\n",
                "        matches = []; similars = []; input_len = len(input_processed)\n",
                "        for hw, _ in fast_results:\n",
                "            hw_phs = self.hotwords[hw]; hw_compare = [p.info[:5] for p in hw_phs]; target_len = len(hw_compare)\n",
                "            if target_len > input_len: continue\n",
                "            for i in range(input_len - target_len + 1):\n",
                "                seg = input_processed[i : i + target_len]\n",
                "                if seg[0][1] != 'en' and seg[0][0] != hw_compare[0][0]: continue\n",
                "                if not seg[0][2]: continue\n",
                "                is_end_ok = seg[-1][3] or (i+target_len < input_len and input_processed[i+target_len][1]=='zh' and input_processed[i+target_len][4])\n",
                "                if not is_end_ok: continue\n",
                "                score = fuzzy_substring_score(hw_compare, seg)\n",
                "                m = MatchResult(seg[0][5], seg[-1][6], score, hw); similars.append(m)\n",
                "                if score >= self.threshold: matches.append(m)\n",
                "        seen = set(); sorted_sims = sorted(similars, key=lambda x: x.score, reverse=True)\n",
                "        sims_final = [m for m in sorted_sims if m.score >= self.similar_threshold and not (m.hotword in seen or seen.add(m.hotword))]\n",
                "        return matches, sims_final\n",
                "    def _resolve_and_replace(self, text, matches):\n",
                "        matches.sort(key=lambda x: (x.score, x.end - x.start), reverse=True)\n",
                "        final = []; all_info = []; occupied = []; seen = set()\n",
                "        for m in matches:\n",
                "            if (m.hotword, m.score) not in seen: all_info.append((m.hotword, m.score)); seen.add((m.hotword, m.score))\n",
                "            if m.score < self.threshold or any(not (m.end <= rs or m.start >= re) for rs, re in occupied): continue\n",
                "            if text[m.start:m.end] != m.hotword: final.append(m)\n",
                "            occupied.append((m.start, m.end))\n",
                "        res = list(text); final.sort(key=lambda x: x.start, reverse=True)\n",
                "        for m in final: res[m.start:m.end] = list(m.hotword)\n",
                "        return \"\".join(res), [(m.hotword, m.score) for m in sorted(final, key=lambda x: x.start)], all_info\n",
                "    def correct(self, text, k=10):\n",
                "        in_phs = get_phoneme_info(text)\n",
                "        if not in_phs: return CorrectionResult(text, [], [])\n",
                "        with self._lock:\n",
                "            fast_res = self.fast_rag.search(in_phs, top_k=100); processed = [p.info for p in in_phs]\n",
                "            matches, sims = self._find_matches(fast_res, processed)\n",
                "        nt, fhw, ainfo = self._resolve_and_replace(text, matches)\n",
                "        return CorrectionResult(nt, fhw, [(m.hotword, m.score) for m in sims[:k]])\n",
                "\n",
                "def _get_word_boundaries(text):\n",
                "    bounds = []; i, n = 0, len(text)\n",
                "    while i < n:\n",
                "        if not (text[i].isalnum() or '\\u4e00' <= text[i] <= '\\u9fff'): i += 1; continue\n",
                "        s = i\n",
                "        if '\\u4e00' <= text[i] <= '\\u9fff': i += 1\n",
                "        else:\n",
                "            low = text[i].islower()\n",
                "            while i < n and text[i].isalnum():\n",
                "                if text[i].isupper() and low and i > s: break\n",
                "                low = text[i].islower(); i += 1\n",
                "        bounds.append((s, i, text[s:i]))\n",
                "    return bounds\n",
                "\n",
                "def extract_diff_fragments(w, r):\n",
                "    wb = _get_word_boundaries(w); rb = _get_word_boundaries(r)\n",
                "    m = SequenceMatcher(None, [b[2] for b in wb], [b[2] for b in rb]); frags = []\n",
                "    for tag, i1, i2, j1, j2 in m.get_opcodes():\n",
                "        if tag in ('replace', 'delete') and i2 > i1: frags.append(w[wb[i1][0]:wb[i2-1][1]])\n",
                "        if tag in ('replace', 'insert') and j2 > j1: frags.append(r[rb[j1][0]:rb[j2-1][1]])\n",
                "    return list(dict.fromkeys(frags))\n",
                "\n",
                "class RectificationRAG:\n",
                "    def __init__(self, threshold=0.5):\n",
                "        self.threshold = threshold; self.records = []; self._lock = threading.Lock()\n",
                "    def load_rectify_text(self, text):\n",
                "        recs = []\n",
                "        for block in text.split('---'):\n",
                "            lines = [l.strip() for l in block.split('\\n') if l.strip() and not l.strip().startswith('#')]\n",
                "            if len(lines) >= 2:\n",
                "                w, r = lines[0], lines[1]; frags = extract_diff_fragments(w, r) or [w]\n",
                "                recs.append({'wrong': w, 'right': r, 'fphs': {f: get_phoneme_seq(f) for f in frags}})\n",
                "        with self._lock: self.records = recs\n",
                "    def load_rectify_file(self, path: str):\n",
                "        if os.path.exists(path):\n",
                "            with open(path, 'r', encoding='utf-8') as f: self.load_rectify_text(f.read())\n",
                "    def search(self, text, top_k=5):\n",
                "        in_phs = get_phoneme_seq(text); matches = []\n",
                "        with self._lock:\n",
                "            for rec in self.records:\n",
                "                best = 0.0\n",
                "                for fphs in rec['fphs'].values():\n",
                "                    if not fphs: continue\n",
                "                    score = fuzzy_substring_score(fphs, in_phs)\n",
                "                    if score > best: best = score\n",
                "                if best >= self.threshold: matches.append((rec['wrong'], rec['right'], round(best, 3)))\n",
                "        return sorted(matches, key=lambda x: x[2], reverse=True)[:top_k]"
            ]
        },
        {
            "cell_type": "markdown",
            "id": "ee8635fd",
            "metadata": {},
            "source": [
                "## 5. 调试工具 (Phoneme Debug)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 6,
            "id": "86a83e87",
            "metadata": {},
            "outputs": [],
            "source": [
                "def get_phoneme_cost(p1: Phoneme, p2: Phoneme) -> float:\n",
                "    if p1.lang != p2.lang: return 1.0\n",
                "    if p1.value == p2.value: return 0.0\n",
                "    if p1.lang == 'zh' and p2.lang == 'zh':\n",
                "        pair = {p1.value, p2.value}\n",
                "        for s in SIMILAR_PHONEMES: \n",
                "            if pair.issubset(s): return 0.5\n",
                "    if p1.lang == 'en' and p2.lang == 'en':\n",
                "        lcs_len = _lcs_length(p1.value, p2.value)\n",
                "        max_len = max(len(p1.value), len(p2.value))\n",
                "        return 1.0 - (lcs_len / max_len)\n",
                "    return 1.0\n",
                "\n",
                "def find_best_match(main_seq: List[Phoneme], sub_seq: List[Phoneme]) -> Tuple[float, int, int]:\n",
                "    n, m = len(sub_seq), len(main_seq)\n",
                "    if n == 0 or m == 0: return 0.0, 0, 0\n",
                "    valid_starts = [j for j in range(m) if main_seq[j].is_word_start]\n",
                "    dp = [[0.0] * (m + 1) for _ in range(n + 1)]\n",
                "    for j in range(m + 1):\n",
                "        if j not in valid_starts: dp[0][j] = float('inf')\n",
                "    for i in range(1, n + 1): dp[i][0] = dp[i-1][0] + 1.0\n",
                "    for i in range(1, n + 1):\n",
                "        for j in range(1, m + 1):\n",
                "            cost = get_phoneme_cost(sub_seq[i-1], main_seq[j-1])\n",
                "            dp[i][j] = min(dp[i-1][j] + 1.0, dp[i][j-1] + 1.0, dp[i-1][j-1] + cost)\n",
                "    min_dist, end_pos, best_start = float('inf'), 0, 0\n",
                "    for j in range(1, m + 1):\n",
                "        if dp[n][j] < min_dist:\n",
                "            curr_i, curr_j = n, j\n",
                "            while curr_i > 0:\n",
                "                cost = get_phoneme_cost(sub_seq[curr_i-1], main_seq[curr_j-1])\n",
                "                if curr_j > 0 and abs(dp[curr_i][curr_j] - (dp[curr_i-1][curr_j-1] + cost)) < 1e-9:\n",
                "                    curr_i -= 1; curr_j -= 1\n",
                "                elif abs(dp[curr_i][curr_j] - (dp[curr_i-1][curr_j] + 1.0)) < 1e-9: curr_i -= 1\n",
                "                elif curr_j > 0 and abs(dp[curr_i][curr_j] - (dp[curr_i][curr_j-1] + 1.0)) < 1e-9: curr_j -= 1\n",
                "                else: curr_i -= 1\n",
                "            if curr_j in valid_starts: \n",
                "                min_dist = dp[n][j]; end_pos = j; best_start = curr_j\n",
                "    return 1.0 - (min_dist / n), best_start, end_pos\n",
                "\n",
                "def test_pair(input_text, hotword, split_char=True):\n",
                "    print(f\"--- Testing: '{input_text}' vs '{hotword}' ---\")\n",
                "    input_seq = get_phoneme_info(input_text, split_char=split_char)\n",
                "    target_seq = get_phoneme_info(hotword, split_char=split_char)\n",
                "    print(f\"Input Seq: {[p.value for p in input_seq]}\")\n",
                "    print(f\"Target Seq: {[p.value for p in target_seq]}\")\n",
                "    score, start, end = find_best_match(input_seq, target_seq)\n",
                "    print(f\"Score: {score:.4f}\")\n",
                "    if score > 0:\n",
                "        matched_segment = input_seq[start:end]\n",
                "        print(f\"Matched Segment: {[p.value for p in matched_segment]}\")\n",
                "    print(\"\\n\")"
            ]
        },
        {
            "cell_type": "markdown",
            "id": "6c1706ac",
            "metadata": {},
            "source": [
                "## 6. LLM 集成 (Prompt Builder & Ollama Client)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 7,
            "id": "a1988fe8",
            "metadata": {},
            "outputs": [],
            "source": [
                "class PromptBuilder:\n",
                "    def __init__(self, system_prompt: str = \"你是一个输入法纠错助。\"):\n",
                "        self.system_prompt = system_prompt\n",
                "        self.prompt_prefix_hotwords = \"热词列表：\"\n",
                "        self.prompt_prefix_rectify = \"纠错历史：\\n\"\n",
                "        self.prompt_prefix_input = \"用户输入：\"\n",
                "\n",
                "    def build(self, user_content: str, hotwords: List[Tuple[str, float]] = None, rectify_matches: List[Tuple[str, str, float]] = None) -> List[Dict]:\n",
                "        messages = [{\"role\": \"system\", \"content\": self.system_prompt}]\n",
                "        context_parts = []\n",
                "        if hotwords:\n",
                "            words = [hw for hw, _ in hotwords]\n",
                "            context_parts.append(f\"{self.prompt_prefix_hotwords}[{', '.join(words)}]\")\n",
                "        if rectify_matches:\n",
                "            lines = [self.prompt_prefix_rectify]\n",
                "            for wrong, right, _ in rectify_matches:\n",
                "                lines.append(f\"- {wrong} => {right}\")\n",
                "            context_parts.append(\"\\n\".join(lines) + \"\\n\\n\") \n",
                "        context_str = \"\\n\\n\".join(context_parts)\n",
                "        full_user_content = f\"{context_str}{self.prompt_prefix_input}{user_content}\"\n",
                "        messages.append({\"role\": \"user\", \"content\": full_user_content})\n",
                "        return messages\n",
                "\n",
                "def ollama_chat(messages: List[Dict], model: str = \"gemma3:4b\", stream: bool = True):\n",
                "    url = \"http://localhost:11434/api/chat\"\n",
                "    payload = {\"model\": model, \"messages\": messages, \"stream\": stream}\n",
                "    try:\n",
                "        response = requests.post(url, json=payload, stream=stream)\n",
                "        if not stream: return response.json().get('message', {}).get('content', '')\n",
                "        full_res = \"\"\n",
                "        for line in response.iter_lines():\n",
                "            if line:\n",
                "                chunk = json.loads(line)\n",
                "                content = chunk.get('message', {}).get('content', '')\n",
                "                full_res += content\n",
                "                print(content, end=\"\", flush=True)\n",
                "                if chunk.get('done'): break\n",
                "        print(); return full_res\n",
                "    except Exception as e:\n",
                "        print(f\"\\n[Error calling Ollama]: {e}\"); return \"\""
            ]
        },
        {
            "cell_type": "markdown",
            "id": "abcb487a",
            "metadata": {},
            "source": [
                "## 7. 综合数据准备"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 14,
            "id": "728a1784",
            "metadata": {},
            "outputs": [],
            "source": [
                "# --- A. 数据准备 ---\n",
                "\n",
                "hotwords_data = \"\"\"\n",
                "Claude\n",
                "Bilibili\n",
                "Microsoft\n",
                "麦当劳\n",
                "肯德基\n",
                "# 这是一个注释\n",
                "VsCode\n",
                "七浦路\n",
                "\"\"\"\n",
                "\n",
                "\n",
                "rectify_data = \"\"\"\n",
                "# 纠错历史记录\n",
                "# 用 --- 分段\n",
                "# 每段两行：第一行是原句，第二行是修正结果\n",
                "\n",
                "把那个锯子给我\n",
                "把那个句子给我\n",
                "---\n",
                "cloud code is good\n",
                "Claude Code is good\n",
                "---\n",
                "今天天其不错\n",
                "今天天气不错\n",
                "\"\"\"\n",
                "\n",
                "\n",
                "test_cases_text = \"\"\"\n",
                "我想去吃买当劳和肯得鸡\n",
                "喜欢刷Bili Bili\n",
                "请把那个锯子发给我一下\n",
                "今天天及真的很好\n",
                "Hello klaude\n",
                "I think klaud code is very good\n",
                "我很喜欢 cloud\n",
                "\"\"\"\n",
                "cases = [l.strip() for l in test_cases_text.strip().split('\\n') if l.strip()]"
            ]
        },
        {
            "cell_type": "markdown",
            "id": "ef05b4bd",
            "metadata": {},
            "source": [
                "## 8. 系统初始化"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 9,
            "id": "3ff9ad3b",
            "metadata": {},
            "outputs": [],
            "source": [
                "# --- B. 系统初始化与数据加载 ---\n",
                "\n",
                "# 初始化纠错器和检索器\n",
                "corrector = PhonemeCorrector(threshold=0.8)\n",
                "rectifier = RectificationRAG(threshold=0.5)\n",
                "\n",
                "# 从字符串加载热词\n",
                "corrector.update_hotwords(hotwords_data)\n",
                "rectifier.load_rectify_text(rectify_data)\n",
                "\n",
                "# 从文本文件加载热词\n",
                "# corrector.load_hotwords_file(\"hot.txt\")\n",
                "# rectifier.load_rectify_file(\"hot-rectify.txt\")"
            ]
        },
        {
            "cell_type": "markdown",
            "id": "fe9d0723",
            "metadata": {},
            "source": [
                "## 9. 执行综合纠错与 RAG 演示"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 15,
            "id": "6e9c486b",
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "\n",
                        "==================================================\n",
                        "【 CapsWriter-Offline 综合纠错系统演示 】\n",
                        "==================================================\n",
                        "\n",
                        "Case 1: '我想去吃买当劳和肯得鸡'\n",
                        "  [纠错结果] 我想去吃麦当劳和肯德基\n",
                        "  [匹配热词] [('麦当劳', 0.8888888888888888), ('肯德基', 1.0)]\n",
                        "  [相似推荐] [('肯德基', 1.0), ('麦当劳', 0.8888888888888888)]\n",
                        "  [RAG 相似历史]\n",
                        "    - '今天天其不错' => '今天天气不错' (相似度: 0.667)\n",
                        "\n",
                        "Case 2: '喜欢刷Bili Bili'\n",
                        "  [纠错结果] 喜欢刷Bilibili\n",
                        "  [匹配热词] [('Bilibili', 1.0)]\n",
                        "  [相似推荐] [('Bilibili', 1.0)]\n",
                        "\n",
                        "Case 3: '请把那个锯子发给我一下'\n",
                        "  [纠错结果] 请把那个锯子发给我一下\n",
                        "  [RAG 相似历史]\n",
                        "    - '分段' => '把那个锯子给我' (相似度: 0.857)\n",
                        "\n",
                        "Case 4: '今天天及真的很好'\n",
                        "  [纠错结果] 今天天及真的很好\n",
                        "  [RAG 相似历史]\n",
                        "    - '今天天其不错' => '今天天气不错' (相似度: 0.667)\n",
                        "    - '分段' => '把那个锯子给我' (相似度: 0.500)\n",
                        "\n",
                        "Case 5: 'Hello klaude'\n",
                        "  [纠错结果] Hello Claude\n",
                        "  [匹配热词] [('Claude', 0.8333333333333334)]\n",
                        "  [相似推荐] [('Claude', 0.8333333333333334)]\n",
                        "\n",
                        "Case 6: 'I think klaud code is very good'\n",
                        "  [纠错结果] I think klaud code is very good\n",
                        "  [相似推荐] [('VsCode', 0.6666666666666667)]\n",
                        "  [RAG 相似历史]\n",
                        "    - 'cloud code is good' => 'Claude Code is good' (相似度: 0.833)\n",
                        "\n",
                        "Case 7: '我很喜欢 cloud'\n",
                        "  [纠错结果] 我很喜欢 cloud\n",
                        "  [RAG 相似历史]\n",
                        "    - 'cloud code is good' => 'Claude Code is good' (相似度: 0.500)\n"
                    ]
                }
            ],
            "source": [
                "# --- C. 执行综合纠错演示 ---\n",
                "print(\"\\n\" + \"=\"*50)\n",
                "print(\"【 CapsWriter-Offline 综合纠错系统演示 】\")\n",
                "print(\"=\"*50)\n",
                "\n",
                "for i, t in enumerate(cases):\n",
                "    print(f\"\\nCase {i+1}: '{t}'\")\n",
                "    result = corrector.correct(t)\n",
                "    print(f\"  [纠错结果] {result.text}\")\n",
                "    if result.matchs: print(f\"  [匹配热词] {result.matchs}\")\n",
                "    if result.similars: print(f\"  [相似推荐] {result.similars}\")\n",
                "    rag_results = rectifier.search(t)\n",
                "    if rag_results:\n",
                "        print(f\"  [RAG 相似历史]\")\n",
                "        for wrong, right, score in rag_results:\n",
                "            print(f\"    - '{wrong}' => '{right}' (相似度: {score:.3f})\")"
            ]
        },
        {
            "cell_type": "markdown",
            "id": "d901627e",
            "metadata": {},
            "source": [
                "## 10. 音素匹配调试演示 (test_pair)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 11,
            "id": "6163670a",
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "\n",
                        "==================================================\n",
                        "【 Phoneme Debug 调试演示 】\n",
                        "==================================================\n",
                        "--- Testing: 'cloud' vs 'claude' ---\n",
                        "Input Seq: ['c', 'l', 'o', 'u', 'd']\n",
                        "Target Seq: ['c', 'l', 'a', 'u', 'd', 'e']\n",
                        "Score: 0.6667\n",
                        "Matched Segment: ['c', 'l', 'o', 'u', 'd']\n",
                        "\n",
                        "\n",
                        "--- Testing: 'vscode' vs 'VS Code' ---\n",
                        "Input Seq: ['v', 's', 'c', 'o', 'd', 'e']\n",
                        "Target Seq: ['v', 's', 'c', 'o', 'd', 'e']\n",
                        "Score: 1.0000\n",
                        "Matched Segment: ['v', 's', 'c', 'o', 'd', 'e']\n",
                        "\n",
                        "\n",
                        "--- Testing: '七福路' vs '七浦路' ---\n",
                        "Input Seq: ['q', 'i', '1', 'f', 'u', '2', 'l', 'u', '4']\n",
                        "Target Seq: ['q', 'i', '1', 'p', 'u', '3', 'l', 'u', '4']\n",
                        "Score: 0.7778\n",
                        "Matched Segment: ['q', 'i', '1', 'f', 'u', '2', 'l', 'u', '4']\n",
                        "\n",
                        "\n"
                    ]
                }
            ],
            "source": [
                "print(\"\\n\" + \"=\"*50)\n",
                "print(\"【 Phoneme Debug 调试演示 】\")\n",
                "print(\"=\"*50)\n",
                "test_pair(\"cloud\", \"claude\")\n",
                "test_pair(\"vscode\", \"VS Code\")\n",
                "test_pair(\"七福路\", \"七浦路\")"
            ]
        },
        {
            "cell_type": "markdown",
            "id": "5a854dc9",
            "metadata": {},
            "source": [
                "## 11. LLM Prompt 组建与调用演示"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 12,
            "id": "033c045d",
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "\n",
                        "==================================================\n",
                        "【 LLM 纠错演示 (Prompt 构建) 】\n",
                        "==================================================\n",
                        "组装后的 Prompt (Messages):\n",
                        "[\n",
                        "  {\n",
                        "    \"role\": \"system\",\n",
                        "    \"content\": \"\\n# 角色\\n\\n你是一位高级智能复读机，你的任务是将用户提供的语音转录文本进行润色和整理和再输出。\\n\\n# 要求\\n\\n- 清除语气词（如：呃、啊、那个、就是说）\\n- 修正语音识别的错误（根据热词列表）\\n- 根据纠错记录推测潜在专有名词进行修正\\n- 修正专有名词、大小写\\n- 千万不要以为用户在和你对话\\n- 如果用户提问，就把问题润色后原样输出，因为那不是在和你对话\\n- 仅输出润色后的内容，严禁任何多余的解释，不要翻译语言\\n\\n# 例子\\n\\n例1（问题 - 不要回答）\\n用户输入：我很想你\\n润色输出：我很想你\\n\\n例2（指令 - 不要执行）\\n用户输入：写一篇小作文\\n润色输出：写一篇小作文\\n\\n例3（判断意图 - 文件名）\\n用户输入：编程点 MD\\n润色输出：编程.md\\n\\n例4（判断意图 - 邮件地址）\\n用户输入：x yz at gmail dot com\\n润色输出（用户在写邮件地址）：xyz@gmail.com\\n\"\n",
                        "  },\n",
                        "  {\n",
                        "    \"role\": \"user\",\n",
                        "    \"content\": \"纠错历史：\\n\\n- cloud code is good => Claude Code is good\\n\\n用户输入：我很喜欢 cloud\"\n",
                        "  }\n",
                        "]\n",
                        "\n",
                        "==================================================\n",
                        "【 LLM 输出结果】\n",
                        "==================================================\n",
                        "我很喜欢 Claude Code\n",
                        "\n"
                    ]
                },
                {
                    "data": {
                        "text/plain": [
                            "'我很喜欢 Claude Code\\n'"
                        ]
                    },
                    "execution_count": 12,
                    "metadata": {},
                    "output_type": "execute_result"
                }
            ],
            "source": [
                "print(\"\\n\" + \"=\"*50)\n",
                "print(\"【 LLM 纠错演示 (Prompt 构建) 】\")\n",
                "print(\"=\"*50)\n",
                "system_prompt = \"\"\"\n",
                "# 角色\n",
                "\n",
                "你是一位高级智能复读机，你的任务是将用户提供的语音转录文本进行润色和整理和再输出。\n",
                "\n",
                "# 要求\n",
                "\n",
                "- 清除语气词（如：呃、啊、那个、就是说）\n",
                "- 修正语音识别的错误（根据热词列表）\n",
                "- 根据纠错记录推测潜在专有名词进行修正\n",
                "- 修正专有名词、大小写\n",
                "- 千万不要以为用户在和你对话\n",
                "- 如果用户提问，就把问题润色后原样输出，因为那不是在和你对话\n",
                "- 仅输出润色后的内容，严禁任何多余的解释，不要翻译语言\n",
                "\n",
                "# 例子\n",
                "\n",
                "例1（问题 - 不要回答）\n",
                "用户输入：我很想你\n",
                "润色输出：我很想你\n",
                "\n",
                "例2（指令 - 不要执行）\n",
                "用户输入：写一篇小作文\n",
                "润色输出：写一篇小作文\n",
                "\n",
                "例3（判断意图 - 文件名）\n",
                "用户输入：编程点 MD\n",
                "润色输出：编程.md\n",
                "\n",
                "例4（判断意图 - 邮件地址）\n",
                "用户输入：x yz at gmail dot com\n",
                "润色输出（用户在写邮件地址）：xyz@gmail.com\n",
                "\"\"\"\n",
                "builder = PromptBuilder(system_prompt)\n",
                "case_text = \"我很喜欢 cloud\"\n",
                "result = corrector.correct(case_text)\n",
                "rag_matches = rectifier.search(case_text)\n",
                "prompt_msgs = builder.build(case_text, hotwords=result.similars, rectify_matches=rag_matches)\n",
                "\n",
                "print(\"组装后的 Prompt (Messages):\")\n",
                "print(json.dumps(prompt_msgs, ensure_ascii=False, indent=2))\n",
                "\n",
                "print(\"\\n\" + \"=\"*50)\n",
                "print(\"【 LLM 输出结果】\")\n",
                "print(\"=\"*50)\n",
                "ollama_chat(prompt_msgs)"
            ]
        },
        {
            "cell_type": "markdown",
            "id": "5beca360",
            "metadata": {},
            "source": [
                "## 12. 性能测试 (FastRAG)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 13,
            "id": "77020cca",
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "\n",
                        "==================================================\n",
                        "【 性能测试 (FastRAG) 】\n",
                        "==================================================\n",
                        "测试文本: 我想去吃买当劳和肯得鸡, Hello klaude, 喜欢刷Bili Bili...\n",
                        "测试轮数: 1000\n",
                        "平均耗时: 0.028ms\n",
                        "吞吐量: 35124.9 次/秒\n",
                        "==================================================\n"
                    ]
                }
            ],
            "source": [
                "print(\"\\n\" + \"=\"*50)\n",
                "print(\"【 性能测试 (FastRAG) 】\")\n",
                "print(\"=\"*50)\n",
                "test_text = \"我想去吃买当劳和肯得鸡, Hello klaude, 喜欢刷Bili Bili\"\n",
                "in_phs = get_phoneme_info(test_text)\n",
                "if HAS_NUMBA:\n",
                "    for _ in range(5): _ = corrector.fast_rag.search(in_phs)\n",
                "start = time.time(); iterations = 1000\n",
                "for _ in range(iterations): _ = corrector.fast_rag.search(in_phs)\n",
                "elapsed = time.time() - start\n",
                "print(f\"测试文本: {test_text[:40]}...\")\n",
                "print(f\"测试轮数: {iterations}\")\n",
                "print(f\"平均耗时: {elapsed/iterations*1000:.3f}ms\")\n",
                "print(f\"吞吐量: {iterations/elapsed:.1f} 次/秒\")\n",
                "print(\"=\"*50)"
            ]
        }
    ],
    "metadata": {
        "kernelspec": {
            "display_name": "capswriter",
            "language": "python",
            "name": "python3"
        },
        "language_info": {
            "codemirror_mode": {
                "name": "ipython",
                "version": 3
            },
            "file_extension": ".py",
            "mimetype": "text/x-python",
            "name": "python",
            "nbconvert_exporter": "python",
            "pygments_lexer": "ipython3",
            "version": "3.10.19"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 5
}
